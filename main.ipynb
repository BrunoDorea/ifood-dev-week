{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dia 1: Conheça o Google Colab e o Projeto Desta Dev Week\n",
    "\n",
    "Vamos mergulhar no Google Colab, aprendendo como ele pode ser usado para automatizar tarefas cotidianas, principalmente através da manipulação de planilhas. Além disso, você aprenderá na prática o conceito do Net Promoter Score (NPS), uma métrica fundamental para entender a satisfação do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pré Analise - Baixar arquivo csv do Google Drive e carregar seus dados em um DataFrame pandas\n",
    "\n",
    "import gdown\n",
    "import pandas as pd\n",
    "\n",
    "file_id = '1_nyLNsT55X37Y0KDBXVXzSYsX-SoSqZi'\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'feedbacks.csv')\n",
    "\n",
    "dados = pd.read_csv('feedbacks.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1 - Implementar a lógica de NPS em comandos simples e sequenciais (imperativo)\n",
    "import pandas as pd\n",
    "\n",
    "notas = dados['nota']\n",
    "\n",
    "detratores = 0\n",
    "promotores = 0\n",
    "\n",
    "for nota in notas:\n",
    "    if nota >= 9:\n",
    "        promotores += 1\n",
    "    elif nota <= 6:\n",
    "        detratores += 1\n",
    "\n",
    "nps = (promotores - detratores) / len(notas) * 100\n",
    "print(nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 2 - Evoluir a implementação para separar melhor as responsabilidades (funcional)\n",
    "import pandas as pd\n",
    "\n",
    "def calcular_nps(notas):\n",
    "    detratores = notas.apply(lambda nota: nota <= 6).sum() # Maneira 1\n",
    "    promotores = notas[notas >=9].count() # Maneira 2\n",
    "\n",
    "    nps = (promotores - detratores) / len(notas) * 100\n",
    "    return nps\n",
    "\n",
    "notas = dados['nota']\n",
    "\n",
    "print(calcular_nps(notas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 3 - Abstrair o problema usando classes e objetos (orientação a objetos)\n",
    "import pandas as pd\n",
    "\n",
    "class Feedback:\n",
    "    def __init__(self, nota, comentario):\n",
    "        self.nota = nota\n",
    "        self.comentario = comentario\n",
    "\n",
    "class AnalisadorFeedback:\n",
    "    def __init__(self, feedbacks):\n",
    "        self.feedbacks = feedbacks\n",
    "\n",
    "    def calcular_nps(self):\n",
    "        detratores = sum([1 for feedback in self.feedbacks if feedback.nota <= 6])\n",
    "        promotores = sum([1 for feedback in self.feedbacks if feedback.nota >= 9])\n",
    "\n",
    "        nps = (promotores - detratores) / len(self.feedbacks) * 100\n",
    "        return nps\n",
    "\n",
    "feedbacks = [Feedback(linha['nota'], linha['comentario']) for i, linha in dados.iterrows()] # Modo 1\n",
    "# feedbacks = dados.apply(lambda linha: Feedback(linha['nota'], linha['comentario']), axis=1) # Modo 2 - Alternativo\n",
    "\n",
    "analisador = AnalisadorFeedback(feedbacks)\n",
    "nps = analisador.calcular_nps()\n",
    "\n",
    "print(nps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dia 2: Desvendando o Poder dos Seus Dados com Python\n",
    "\n",
    "No segundo dia, vamos conectar nosso Google Colab ao Google Drive, extrair dados do NPS e aplicar as técnicas de ETL (Extração, Transformação e Carregamento) nesses dados. Com a ajuda da biblioteca matplotlib, criaremos gráficos para visualizar e compreender o nível de satisfação dos nossos usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar gráfico usando \"matplotlib\" para visualizar o NPS que calculamos no Dia 1\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Definição das constantes que usaremos para visualizar o NPS\n",
    "NPS_ZONAS =   ['Crítico', 'Aperfeiçoamento', 'Qualidade', 'Excelência']\n",
    "NPS_VALORES = [-100, 0, 50, 75, 100]\n",
    "NPS_CORES =   ['#FF595E', '#FFCA3A', '#8AC926', '#1982C4']\n",
    "\n",
    "def gerar_grafico_nps(nps):\n",
    "    fig, ax = plt.subplots(figsize=(10, 2))\n",
    "    \n",
    "    for i, zona in enumerate(NPS_ZONAS):\n",
    "        ax.barh([0], width=NPS_VALORES[i+1]-NPS_VALORES[i], left=NPS_VALORES[i], color=NPS_CORES[i])\n",
    "\n",
    "    ax.barh([0], width=1, left=nps, color='black')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(NPS_VALORES)\n",
    "    ax.set_xlim(-100, 100)\n",
    "\n",
    "    plt.text(nps, 0, f'NPS: {nps: .0f}', ha='center', va='center', color='white', bbox=dict(facecolor='black'))\n",
    "\n",
    "    patches = [mpatches.Patch(color=NPS_CORES[i], label=NPS_ZONAS[i]) for i in range(len(NPS_ZONAS))]\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1,1))\n",
    "    plt.title('NPS Score - iFood Dev Week')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "gerar_grafico_nps(nps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dia 3: Decifrando Sentimentos com Inteligência Artificial (IA)\n",
    "\n",
    "No último dia, vamos utilizar as técnicas de Processamento de Linguagem Natural (PLN) para analisar os sentimentos expressos nos comentários associados às notas de NPS. Dessa forma, teremos uma perspectiva qualitativa que complementa nossos dados quantitativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: API Key da OpenAI\n",
    "openai_api_key = 'API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Integrar com o ChatGPT e usá-lo como um modelo para análise de sentimentos dos nossos comentários.\n",
    "import openai\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "def analisar_sentimentos(feedbacks):\n",
    "\n",
    "    comentarios_formatados = \"\\n\".join(f\"- Nota {feedback.nota} - {feedback.comentario}\" for feedback in feedbacks)\n",
    "    prompt = f\"Analise dos seguintes comentários, classificando-o como Positivo, Neutro ou Negativo:\\n{comentarios_formatados}\"\n",
    "\n",
    "    respostaAPI = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=20,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"Você é um modelo de análise de sentimentos com foco em feedbacks sobre experiências educacionais.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    return respostaAPI.choices[0].message.content\n",
    "\n",
    "insigths = analisar_sentimentos(feedbacks)\n",
    "print(insigths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
